{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d036f7d",
   "metadata": {},
   "source": [
    "# Dataset Features\n",
    "The training data contains the following engineered and raw features:\n",
    "\n",
    "- **MAF**\n",
    "- **R2**\n",
    "- **het**\n",
    "- **platform**\n",
    "- **cluster**\n",
    "- **GERP_RS**\n",
    "- **GERP_NR**\n",
    "- **GERP_RS_rankscore**\n",
    "- **gnomADe_AF**\n",
    "- **synonymous**\n",
    "- **SIFT**\n",
    "- **gnomADg_AF**\n",
    "- **IMPACT**\n",
    "- **protein_coding**\n",
    "- **LCR** (True if in LCR, else False)\n",
    "- **type** (Genotyped / Imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import gc\n",
    "import xgboost, catboost, lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loading \n",
    "df = pd.read_csv('data.csv') # described above\n",
    "\n",
    "# Derived variables\n",
    "df['synonymous']   = df['CSQ'] == 'synonymous_variant'\n",
    "df['protein_coding'] = df['BIOTYPE'] == 'protein_coding'\n",
    "df['het'] = df['het.x'] / (df['hom_alt.x'] + df['hom_ref.x'] + df['het.x'])\n",
    "\n",
    "# Target variable\n",
    "y_clf = (df['p_flag'] == 'Discordant').astype(int)\n",
    "\n",
    "FEATURES = ['MAF','R2','het','platform','cluster','GERP_RS','GERP_NR','GERP_RS_rankscore',\n",
    "            'gnomADe_AF','synonymous','SIFT','gnomADg_AF','IMPACT','protein_coding','LCR','type']\n",
    "\n",
    "# One‚Äëhot encode categoricals\n",
    "X = pd.get_dummies(df[FEATURES], drop_first=True)\n",
    "\n",
    "# Train / test split with oversampling on training fold\n",
    "ros = RandomOverSampler(random_state=666)\n",
    "stratifier = df[['p_flag','platform','cluster']].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_clf, test_size=0.20, random_state=666, stratify=stratifier\n",
    ")\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ccb977",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fafc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODELS = {\n",
    "    'xgboost'  : {'lib':'xgboost.XGBClassifier',  'n_trials': 50},\n",
    "    'lightgbm' : {'lib':'lightgbm.LGBMClassifier', 'n_trials': 50},\n",
    "    'catboost' : {'lib':'catboost.CatBoostClassifier', 'n_trials': 50}, \n",
    "}\n",
    "\n",
    "def optimise_model(name, lib_path, n_trials=1):\n",
    "\n",
    "    module_path, cls_name = lib_path.rsplit('.',1)\n",
    "    cls = __import__(module_path, fromlist=[cls_name]).__dict__[cls_name]\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        if name == 'xgboost':\n",
    "            params = {\n",
    "                'max_depth'       : trial.suggest_int('max_depth', 3, 15),\n",
    "                'min_child_weight': trial.suggest_float('min_child_weight', 1e-2, 10.0, log=True),\n",
    "                'gamma'           : trial.suggest_float('gamma', 0.0, 5.0),                        \n",
    "                'learning_rate'   : trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
    "                'n_estimators'    : trial.suggest_int('n_estimators', 100, 1000),              \n",
    "                'subsample'       : trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha'       : trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),        \n",
    "                'reg_lambda'      : trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),        \n",
    "                'objective'       : 'binary:logistic',\n",
    "                'eval_metric'     : 'logloss',\n",
    "                'random_state'    : 666,\n",
    "                'n_jobs'          : -1,\n",
    "                'verbosity'       : 0,\n",
    "            }\n",
    "\n",
    "        elif name == 'lightgbm':\n",
    "            params = {\n",
    "                'boosting_type'   : 'gbdt',\n",
    "                'max_depth'       : trial.suggest_int('max_depth', 2, 15), \n",
    "                'num_leaves'      : trial.suggest_int('num_leaves', 16, 512),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),  \n",
    "                'min_split_gain'  : trial.suggest_float('min_split_gain', 0.0, 1.0),  \n",
    "                'learning_rate'   : trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
    "                'n_estimators'    : trial.suggest_int('n_estimators', 100, 1000),\n",
    "                'subsample'       : trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha'       : trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),        \n",
    "                'reg_lambda'      : trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),         \n",
    "                'objective'       : 'binary',\n",
    "                'metric'          : 'binary_logloss',\n",
    "                'random_state'    : 666,\n",
    "                'n_jobs'          : -1,\n",
    "                'verbosity'       : -1,\n",
    "            }\n",
    "\n",
    "        else:  # catboost\n",
    "            params = {\n",
    "                'depth'           : trial.suggest_int('depth', 3, 15),\n",
    "                'learning_rate'   : trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
    "                'iterations'      : trial.suggest_int('iterations', 100, 1000),       \n",
    "                'l2_leaf_reg'     : trial.suggest_float('l2_leaf_reg', 1, 10, log=True),\n",
    "                'random_strength' : trial.suggest_float('random_strength', 1e-3, 10.0, log=True),\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),    \n",
    "                'border_count'    : trial.suggest_int('border_count', 32, 255),       \n",
    "                'loss_function'   : 'Logloss',\n",
    "                'eval_metric'     : 'Logloss',\n",
    "                'random_state'    : 666,\n",
    "                'verbose'         : False,\n",
    "            }\n",
    "\n",
    "        model = cls(**params)\n",
    "        if name=='catboost':    \n",
    "            model.fit(X_train, y_train, verbose=False)\n",
    "            preds = model.predict_proba(X_test)[:,1]\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "        return roc_auc_score(y_test, preds)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    best_score = study.best_value\n",
    "    best_params = study.best_params\n",
    "\n",
    "    if name=='xgboost':\n",
    "        best_params.update({'objective':'binary:logistic','eval_metric':'logloss',\n",
    "                            'random_state':666,'n_jobs':-1, 'verbosity': 0})\n",
    "    elif name=='lightgbm':\n",
    "        best_params.update({'boosting_type':'gbdt','objective':'binary',\n",
    "                            'random_state':666,'n_jobs':-1,'verbosity':-1})\n",
    "    else:\n",
    "        best_params.update({'random_state':666, 'verbose':False, 'loss_function':'Logloss'})\n",
    "\n",
    "    final_model = cls(**best_params).fit(X_train, y_train)\n",
    "    y_pred_bin  = (final_model.predict_proba(X_test)[:,1] >= 0.5).astype(int)\n",
    "\n",
    "    report = classification_report(y_test, y_pred_bin, output_dict=True, zero_division=0)\n",
    "    return {\n",
    "        'model'        : final_model,\n",
    "        'roc_auc'      : best_score,\n",
    "        'f1'           : report['1']['f1-score'],\n",
    "        'accuracy'     : report['accuracy'],\n",
    "        'best_params'  : best_params,\n",
    "    }\n",
    "\n",
    "results = {}\n",
    "for mname, cfg in MODELS.items():\n",
    "    print(f'‚è≥ Optimising {mname}...')\n",
    "    results[mname] = optimise_model(mname, cfg['lib'], cfg['n_trials'])\n",
    "\n",
    "import pandas as pd, json, pprint, numpy as np\n",
    "summary = pd.DataFrame({k:{'ROC-AUC':v['roc_auc'],\n",
    "                           'F1':v['f1'],\n",
    "                           'Accuracy':v['accuracy']} for k,v in results.items()}).T\n",
    "print('\\nPerformance (test set):')\n",
    "display(summary.sort_values('ROC-AUC', ascending=False))\n",
    "\n",
    "winner = summary['ROC-AUC'].idxmax()\n",
    "print(f'\\nüèÜ Best model: **{winner}**')\n",
    "print('Tuned hyper-parameters:')\n",
    "pprint.pprint(results[winner]['best_params'])\n",
    "\n",
    "from importlib import import_module\n",
    "module_path, cls_name = MODELS[winner]['lib'].rsplit('.',1)\n",
    "winner_model_cls = import_module(module_path).__dict__[cls_name]\n",
    "best_params = results[winner]['best_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b60b4",
   "metadata": {},
   "source": [
    "# Leave-one-chromosome-out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bae0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chrom'] = df['chr_pos_gt'].str.split(':', n=1).str[0].str.replace('chr','', regex=False)\n",
    "chromosomes = sorted(df['chrom'].unique(), key=lambda x: (not x.isdigit(), int(x) if x.isdigit() else x))\n",
    "\n",
    "X_full = pd.get_dummies(df[FEATURES], drop_first=True)\n",
    "y_full = y_clf.values\n",
    "\n",
    "per_chr_auc = {}\n",
    "plt.figure(figsize=(6,5))\n",
    "\n",
    "for chrom in chromosomes:\n",
    "    train_idx = df['chrom'] != chrom\n",
    "    test_idx  = df['chrom'] == chrom\n",
    "\n",
    "    model = winner_model_cls(**best_params)\n",
    "    model.fit(X_full[train_idx], y_full[train_idx])\n",
    "\n",
    "    y_prob = model.predict_proba(X_full[test_idx])[:,1]\n",
    "    auc = roc_auc_score(y_full[test_idx], y_prob)\n",
    "    per_chr_auc[chrom] = auc\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_full[test_idx], y_prob)\n",
    "    plt.plot(fpr, tpr, alpha=0.3, label=f'chr{chrom} (AUC {auc:.2f})')\n",
    "\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel('False-positive rate')\n",
    "plt.ylabel('True-positive rate')\n",
    "plt.title('Leave-One-Chromosome-Out ROC curves')\n",
    "plt.legend(fontsize='xx-small', bbox_to_anchor=(1.02,1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('AUC per chromosome:')\n",
    "for c, a in per_chr_auc.items():\n",
    "    print(f'  chr{c:>2}: {a:.3f}')\n",
    "print(f\"\\nMean AUC = {np.mean(list(per_chr_auc.values())):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_all, y_prob_all = [], []\n",
    "\n",
    "for chrom in chromosomes:\n",
    "    train_idx = df['chrom'] != chrom\n",
    "    test_idx  = df['chrom'] == chrom\n",
    "\n",
    "    model = winner_model_cls(**best_params)\n",
    "    model.fit(X_full[train_idx], y_full[train_idx])\n",
    "\n",
    "    y_true_all.append(y_full[test_idx])\n",
    "    y_prob_all.append(model.predict_proba(X_full[test_idx])[:, 1])\n",
    "\n",
    "    del model; gc.collect()\n",
    "\n",
    "y_true_all = np.concatenate(y_true_all)\n",
    "y_prob_all = np.concatenate(y_prob_all)\n",
    "y_pred_all = (y_prob_all >= 0.5).astype(int)\n",
    "print(classification_report(y_true_all, y_pred_all, digits=3, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d53e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = winner_model_cls(**best_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "if hasattr(model, \"feature_importances_\"):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1][:20]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.barh(range(len(indices))[::-1], importances[indices])\n",
    "    plt.yticks(range(len(indices))[::-1], X_train.columns[indices])\n",
    "    plt.title(\"Top 20 Feature Importances\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"The winning model does not expose feature_importances_.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
